{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdy8g0UslQBw"
   },
   "source": [
    "# LOCA Interploation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4516,
     "status": "ok",
     "timestamp": 1599734107778,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "GRxt7ptWlQBy"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "from scipy import spatial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "\n",
    "import torchvision\n",
    "from torch.autograd import grad\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CIyflFDdlQB3"
   },
   "source": [
    "## Data generation and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1599734175157,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "EYJKvDcIlQB6"
   },
   "outputs": [],
   "source": [
    "def deformation(x):\n",
    "    #This function transforms the data which the encoder of the LOCA has to invert and the decoder has to reapply.\n",
    "    y = np.empty((2))\n",
    "    y[0] = x[0] + x[1]**3\n",
    "    y[1] = x[1] - x[0]**3\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 815,
     "status": "ok",
     "timestamp": 1599734175158,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "OwhVXSjelQB9"
   },
   "outputs": [],
   "source": [
    "def samples_test(size= 200, samples=20000, sig_sq=0.0001):\n",
    "    #This function generates the data, in the form of clouds around a given number of anchor points in a square. \n",
    "    #This data will be used as the test data.\n",
    "    center = np.empty(shape = (samples, 2))\n",
    "    points = np.empty(shape = (samples, size, 2))\n",
    "    \n",
    "    for i in range(samples):        \n",
    "        center[i, ::] = np.random.uniform(low=-0.025, high=1.025, size=(2))\n",
    "        pts = np.random.multivariate_normal(center[i, ::], [[sig_sq,0],[0,sig_sq]], size=size)\n",
    "       \n",
    "        points[i, ::, 0] = pts[::, 0] \n",
    "        points[i, ::, 1] = pts[::, 1] \n",
    "       \n",
    "    return points, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1599734175572,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "2RZFqvDsVEsH"
   },
   "outputs": [],
   "source": [
    "def samples_train(size= 200, samples=2000, sig_sq=0.0001):\n",
    "    #This function generates the data, in the form of clouds around a given number of anchor points in a hollow square. \n",
    "    #This data will be used as the training data.\n",
    "    center = np.empty(shape = (samples, 2))\n",
    "    points = np.empty(shape = (samples, size, 2))\n",
    "    \n",
    "    for i in range(samples):\n",
    "        side_list = ['rigth','top','left','bottom']\n",
    "        side = random.choice(side_list)\n",
    "        if side == 'rigth':\n",
    "            center[i, ::] = np.random.uniform(low=[0, 0.1], high=[0.1, 1], size=(2))\n",
    "        if side == 'top':\n",
    "            center[i, ::] = np.random.uniform(low=[0.1, 0.9], high=[1, 1], size=(2))\n",
    "        if side == 'left':\n",
    "            center[i, ::] = np.random.uniform(low=[0.9, 0.9], high=[1, 0], size=(2))\n",
    "        if side == 'bottom':\n",
    "            center[i, ::] = np.random.uniform(low=[0.9, 0.1], high=[0, 0], size=(2))\n",
    "            \n",
    "        pts = np.random.multivariate_normal(center[i, ::], [[sig_sq,0],[0,sig_sq]], size=size)\n",
    "       \n",
    "        points[i, ::, 0] = pts[::, 0] \n",
    "        points[i, ::, 1] = pts[::, 1] \n",
    "       \n",
    "    return points, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2759,
     "status": "ok",
     "timestamp": 1599734177632,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "zpLTowiOlQCC",
    "outputId": "b5d834ea-98c3-464f-dff6-d2f1fa71fa1c"
   },
   "outputs": [],
   "source": [
    "#Calling the data generation function and visualizing the results.\n",
    "points, center = samples_train(size= 200, samples=2000, sig_sq=0.0001)\n",
    "points_plt = np.reshape(points, (points.shape[0]*points.shape[1], 2))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Untransformed Data')\n",
    "\n",
    "ax.scatter(center[::, 0], center[::, 1], c='g', alpha=1, s = 4)\n",
    "ax.scatter(points_plt[::, 0], points_plt[::, 1], c='b', alpha=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5246,
     "status": "ok",
     "timestamp": 1599734180391,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "yjniQ9OslQCI",
    "outputId": "9fb39714-93d9-46af-8ae7-f0f5d50c113d"
   },
   "outputs": [],
   "source": [
    "#Applying the transformation and rescaling the data to create the final training data.\n",
    "sig_sq=0.0001\n",
    "size = 200 \n",
    "\n",
    "tran_sq = np.empty_like(points)\n",
    "tran_cent = np.empty_like(center)\n",
    "\n",
    "for i in range(points.shape[0]):\n",
    "    tran_cent[i, ::] =  deformation(center[i, ::])\n",
    "    tran_cent[i, 0 ] = tran_cent[i, 0] - 1\n",
    "    for j in range(points.shape[1]):\n",
    "        tran_sq[i, j, ::] = deformation(points[i, j, ::])\n",
    "        tran_sq[i, j, 0 ] = tran_sq[i, j, 0] - 1 \n",
    "\n",
    "tran_sq_plt = np.reshape(tran_sq, (tran_sq.shape[0]*tran_sq.shape[1], 2))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Model Input')\n",
    "ax.scatter(tran_cent[::, 0], tran_cent[::, 1], c='g', alpha=1, s = 4)\n",
    "ax.scatter(tran_sq[::, ::, 0], tran_sq[::, ::, 1], c='b', alpha=0.006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2PjYNSWblQCL"
   },
   "source": [
    "### Defining the whitening loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4388,
     "status": "ok",
     "timestamp": 1599734180392,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "bPMJF6yDlQCM"
   },
   "outputs": [],
   "source": [
    "def cov(m, rowvar=False):\n",
    "    #This function calculates the covariance matrix which is needed in the loss function of the encoder.\n",
    "    if not rowvar and m.size(0) != 1:\n",
    "        m = m.t()\n",
    "    fact = 1.0 / (m.size(1) - 1)\n",
    "    m_sub_mean = m - torch.mean(m, dim=1, keepdim=True)\n",
    "    mt = m_sub_mean.t()  # if complex: mt = m.t().conj()\n",
    "    m_mul = m_sub_mean.matmul(mt)\n",
    "    f_m_mul = fact * m_mul\n",
    "    cov_mat = f_m_mul.squeeze()\n",
    "    return cov_mat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2651,
     "status": "ok",
     "timestamp": 1599734180393,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "g_5GCoHRpIbD"
   },
   "outputs": [],
   "source": [
    "def loss_whiten(outputs_en):\n",
    "    #This function calculates the whitening loss for the encoder.\n",
    "    L_un = 0\n",
    "    clouds = torch.reshape(outputs_en, (batch_cloud_num, -1, 2))\n",
    "    #interate through all the other points.\n",
    "    for d in range(batch_cloud_num):\n",
    "        #calculate the covariance\n",
    "        C = cov(clouds[d, ::, ::])\n",
    "        #calculate the summed loss\n",
    "        L = ((torch.norm(1/sig_sq*C-torch.eye(2).cuda()))**2)\n",
    "        L_un = L_un + L\n",
    "\n",
    "    #norm the loss by the batch size\n",
    "    L_w = L_un/batch_cloud_num\n",
    "    return L_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2303,
     "status": "ok",
     "timestamp": 1599734180394,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "P3Cl7xvpcL4N"
   },
   "outputs": [],
   "source": [
    "def loss_recon(outputs_de, batch_features):\n",
    "    #This function calculates the reconstruction loss.\n",
    "    clouds_recon = torch.reshape(outputs_de, (batch_cloud_num, -1, 2))\n",
    "    clouds_real = torch.reshape(batch_features, (batch_cloud_num, -1, 2))\n",
    "\n",
    "    #calculate the summed loss\n",
    "    L = torch.norm(clouds_recon[::, ::, ::]-clouds_real[::, ::, ::])**2\n",
    "\n",
    "    #norm the loss by the batch size\n",
    "    L_r = L/(batch_cloud_num*size)\n",
    "    return L_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwqazqAClQCZ"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1427,
     "status": "ok",
     "timestamp": 1599734180395,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "Vi7IMWqslQCa"
   },
   "outputs": [],
   "source": [
    "#The Data is reshaped and the data loaders are created. \n",
    "batch_cloud_num = 200\n",
    "batch_size = batch_cloud_num*tran_sq.shape[1]\n",
    "valdation = tran_sq[:200, ::, ::]\n",
    "tran_sq = tran_sq[200:, ::, ::]\n",
    "\n",
    "val_dataset = np.reshape(valdation, (valdation.shape[0]*valdation.shape[1], valdation.shape[2]))\n",
    "\n",
    "train_dataset = np.reshape(tran_sq, (tran_sq.shape[0]*tran_sq.shape[1], tran_sq.shape[2]))\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "input_shape = train_dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1599734180395,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "hv0pAfdwlQCe"
   },
   "outputs": [],
   "source": [
    "#The LOCA Network is created\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features= 50)\n",
    "        \n",
    "        self.encoder_hidden_layer1 = nn.Linear(\n",
    "            in_features= 50, out_features= 50)\n",
    "        \n",
    "        self.encoder_hidden_layer2 = nn.Linear(\n",
    "            in_features= 50, out_features= 2)\n",
    "        \n",
    "        self.encoder_hidden_layer3 = nn.Linear(\n",
    "            in_features= 2, out_features= 2)\n",
    "        \n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features= 2, out_features= 2)\n",
    "        \n",
    "        self.decoder_input_layer = nn.Linear(\n",
    "            in_features= 2, out_features= 2)\n",
    "        \n",
    "        self.decoder_hidden_layer1 = nn.Linear(\n",
    "            in_features= 2, out_features= 50)\n",
    "        \n",
    "        self.decoder_hidden_layer2 = nn.Linear(\n",
    "            in_features= 50, out_features= 50)\n",
    "        \n",
    "        self.decoder_hidden_layer3 = nn.Linear(\n",
    "            in_features= 50, out_features= input_shape)    \n",
    "        \n",
    "        self.decoder_output_layer = nn.Linear(\n",
    "            in_features= input_shape, out_features=kwargs[\"input_shape\"])\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward_encoder(self, features):\n",
    "        n_e1 = self.encoder_input_layer(features)\n",
    "        a_e1 = self.tanh(n_e1)\n",
    "        \n",
    "        n_e2 = self.encoder_hidden_layer1(a_e1)\n",
    "        a_e2 = self.tanh(n_e2)\n",
    "        \n",
    "        n_e3 = self.encoder_hidden_layer2(a_e2)\n",
    "        a_e3 = self.tanh(n_e3)\n",
    "        \n",
    "        n_e4 = self.encoder_hidden_layer3(a_e3)\n",
    "        \n",
    "        outputs_en = self.encoder_output_layer(n_e4)\n",
    "        \n",
    "        return outputs_en\n",
    "    \n",
    "    def forward_decoder(self, outputs_en):\n",
    "        n_d1 = self.decoder_input_layer(outputs_en)\n",
    "        a_d1 = self.tanh(n_d1)\n",
    "        \n",
    "        n_d2 = self.decoder_hidden_layer1(a_d1)\n",
    "        a_d2 = self.tanh(n_d2)\n",
    "        \n",
    "        n_d3 = self.decoder_hidden_layer2(a_d2)\n",
    "        a_d3 = self.tanh(n_d3)\n",
    "        \n",
    "        n_d4 = self.decoder_hidden_layer3(a_d3)\n",
    "        \n",
    "        reconstructed = self.decoder_output_layer(n_d4)\n",
    "        \n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1599734180732,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "WLmcJoRxrd6a"
   },
   "outputs": [],
   "source": [
    "#The weigths are initialized based on the xavier scheme, \n",
    "#which is preferable to the He scheme that is the default in Pytorch that is optimized for the RELU function.\n",
    "def init_weights(net):\n",
    "    if type(net) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(net.weight)\n",
    "\n",
    "init_weights(AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10427,
     "status": "ok",
     "timestamp": 1599734191004,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "mYu3ONy2lQCh"
   },
   "outputs": [],
   "source": [
    "# Create the necessary objects for the neural network.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model_ae = AE(input_shape=input_shape).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer_ae = optim.Adam(model_ae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 724476,
     "status": "error",
     "timestamp": 1599734908853,
     "user": {
      "displayName": "Carl Müller",
      "photoUrl": "",
      "userId": "13637530209006951077"
     },
     "user_tz": -120
    },
    "id": "V0y20pwKu3F2",
    "outputId": "92efa190-78b1-4985-bbc7-46b1af23e5d6"
   },
   "outputs": [],
   "source": [
    "#This is the training loop of the network.\n",
    "epochs = 100\n",
    "\n",
    "#Create lists of training metrics\n",
    "epoch_list = []\n",
    "val_whiten = []\n",
    "val_recon = []\n",
    "val_total = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_en = 0\n",
    "    train_loss_de = 0\n",
    "    loss = 0\n",
    "    if epoch % 2 == 0:\n",
    "        for batch_features in train_loader:\n",
    "            # Encoder training\n",
    "            # load it to the active device\n",
    "            batch_features = batch_features.to(device)\n",
    "            optimizer_ae.zero_grad()\n",
    "            # compute reconstructions\n",
    "            outputs_en = model_ae.forward_encoder(batch_features.float())\n",
    "            # compute training reconstruction loss\n",
    "            train_loss_en = loss_whiten(outputs_en)\n",
    "            \n",
    "            # compute accumulated gradients\n",
    "            train_loss_en.backward()\n",
    "\n",
    "            # perform parameter update based on current gradients\n",
    "            optimizer_ae.step()\n",
    "\n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            loss += train_loss_en.item()\n",
    "    else:\n",
    "        for batch_features in train_loader:\n",
    "            # Encoder training\n",
    "            # load it to the active device\n",
    "            batch_features = batch_features.to(device)\n",
    "            optimizer_ae.zero_grad()\n",
    "            \n",
    "            for param in model_ae.encoder_input_layer.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model_ae.encoder_hidden_layer1.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model_ae.encoder_hidden_layer2.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model_ae.encoder_hidden_layer3.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model_ae.encoder_output_layer.parameters():\n",
    "                param.requires_grad = False\n",
    "            # compute reconstructions\n",
    "            outputs_en = model_ae.forward_encoder(batch_features.float())\n",
    "            outputs_de = model_ae.forward_decoder(outputs_en.float())\n",
    "            # compute training reconstruction loss\n",
    "            train_loss_de = loss_recon(outputs_de.double(), batch_features.double())\n",
    "            # compute accumulated gradients\n",
    "            train_loss_de.backward()\n",
    "\n",
    "            # perform parameter update based on current gradients\n",
    "            optimizer_ae.step()\n",
    "            \n",
    "            for param in model_ae.encoder_input_layer.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model_ae.encoder_hidden_layer1.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model_ae.encoder_hidden_layer2.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model_ae.encoder_hidden_layer3.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model_ae.encoder_output_layer.parameters():\n",
    "                param.requires_grad = True\n",
    "            # add the mini-batch training loss to epoch loss\n",
    "            loss += train_loss_de.item()\n",
    "    if (epoch % 50) == 0:\n",
    "        #Validate the models performance\n",
    "        val_loss_en = 0 \n",
    "        val_loss_de = 0\n",
    "\n",
    "        for batch_val in test_loader:\n",
    "            batch_val = batch_val.to(device)\n",
    "            outputs_en_val = model_ae.forward_encoder(batch_val.float())\n",
    "            outputs_de_val = model_ae.forward_decoder(outputs_en_val.float())\n",
    "            val_loss_en = loss_whiten(outputs_en_val)\n",
    "            val_loss_de = loss_recon(outputs_de_val.double(), batch_val.double())\n",
    "\n",
    "        val_loss_en = val_loss_en.cpu().detach().numpy()/len(test_loader)\n",
    "        val_loss_de = val_loss_de.cpu().detach().numpy()/len(test_loader)\n",
    "\n",
    "        val_whiten.append(val_loss_en)\n",
    "        val_recon.append(val_loss_de)\n",
    "        val_total.append(val_loss_en + val_loss_de)\n",
    "        epoch_list.append(epoch)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(epoch_list, val_whiten, 'g', label = \"Whitening Loss\")\n",
    "        ax.plot(epoch_list, val_recon, 'r', label = \"Reconstruction Loss\")\n",
    "        ax.set(xlabel='Epochs', ylabel='Loss',\n",
    "              title='Loss over time')\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "        fig.savefig(\"test.png\")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Validation: epoch : {}/{}, loss_whiten = {:.4f}, loss_recon = {:.4f}\".format(epoch, epochs, val_loss_en, val_loss_de))\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_ae.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_ae.state_dict(),\n",
    "            'loss': loss\n",
    "            }, \"/content/drive/My Drive/Colab Notebooks/62_Epoch_\"+str(epoch))\n",
    "\n",
    "        if epoch >= 50:\n",
    "              if all(i <= val_total[-1] for i in val_total[-10:-1]):\n",
    "\n",
    "                  torch.save({\n",
    "                      'epoch': epoch,\n",
    "                      'model_state_dict': model_ae.state_dict(),\n",
    "                      'optimizer_state_dict': optimizer_ae.state_dict(),\n",
    "                      'loss': loss\n",
    "                      }, \"/content/drive/My Drive/Colab Notebooks/62_best\")\n",
    "                  break \n",
    "\n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.4f}, loss_whiten = {:.4f}, loss_recon = {:.4f}\".format(epoch + 1, epochs, loss, train_loss_en, train_loss_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgrAN9LhTnZO"
   },
   "outputs": [],
   "source": [
    "#Saving of the model if needed.\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_ae.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_ae.state_dict(),\n",
    "            'loss': loss\n",
    "            }, \"/content/drive/My Drive/Colab Notebooks/6_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSd5TGqnTor-"
   },
   "outputs": [],
   "source": [
    "#Loading of the model if needed.\n",
    "model_ae = AE(input_shape=input_shape).to(device)\n",
    "optimizer_ae = optim.Adam(model_ae.parameters(), lr=1e-4)\n",
    "\n",
    "checkpoint = torch.load(\"/content/drive/My Drive/Colab Notebooks/Plane_Epoch_1300\")\n",
    "model_ae.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_ae.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model_ae.eval()\n",
    "# - or -\n",
    "#model_ae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1tmol_-lQCn"
   },
   "outputs": [],
   "source": [
    "#Pass the training data set through the model decoder and encoder\n",
    "pred = np.empty_like(train_dataset)\n",
    "for i in range(train_dataset.shape[0]):\n",
    "    Input_1 = torch.from_numpy(train_dataset[i, ::].flatten()).float()\n",
    "    outputs_en = model_ae.forward_encoder(Input_1.cuda())\n",
    "    outputs_de = model_ae.forward_decoder(outputs_en.float())\n",
    "    pred_burst = np.reshape(outputs_de.cpu().detach().numpy(), (int(outputs_de.cpu().detach().numpy().shape[0]/2), 2))\n",
    "    pred[i, ::] = pred_burst\n",
    "pred = np.reshape(pred, (tran_sq.shape[0], tran_sq.shape[1], tran_sq.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FwX960F1lQCr"
   },
   "outputs": [],
   "source": [
    "#Plot the reconstructed training data set.\n",
    "data_sterio_flatt = np.reshape(pred, (pred.shape[0]*pred.shape[1], 2))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Decoder Output')\n",
    "\n",
    "ax.scatter(data_sterio_flatt[::, 0], data_sterio_flatt[::, 1], c='g', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCyI_eaDlQCu"
   },
   "outputs": [],
   "source": [
    "#Pass the training data set through the model encoder\n",
    "pred_encode = np.empty_like(train_dataset)\n",
    "for i in range(pred_encode.shape[0]):\n",
    "    Input_1 = torch.from_numpy(train_dataset[i, ::].flatten()).float()\n",
    "    outputs_en = model_ae.forward_encoder(Input_1.cuda())\n",
    "    pred_burst = np.reshape(outputs_en.cpu().detach().numpy(), (int(outputs_en.cpu().detach().numpy().shape[0]/2), 2))\n",
    "    pred_encode[i, ::] = pred_burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flYoTdT3lQCy"
   },
   "outputs": [],
   "source": [
    "#Plot the standardised untransformed data set.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Encoder Output')\n",
    "ax.scatter(pred_encode[::, 0], pred_encode[::, 1], c='b', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tu83kLLSFqpe"
   },
   "outputs": [],
   "source": [
    "def distance_plot(samples = 300):\n",
    "    #This function computes the pairwise distance between points in the undelaying manifold and the encoder output, \n",
    "    #to schow how well the model is able to find the underlaying manifold a´by checking the isometry of the transformation.\n",
    "    pred_encode = np.empty_like(train_dataset)\n",
    "    for i in range(pred_encode.shape[0]):\n",
    "        Input_1 = torch.from_numpy(train_dataset[i, ::].flatten()).float()\n",
    "        outputs_en = model_ae.forward_encoder(Input_1.cuda())\n",
    "        pred_burst = np.reshape(outputs_en.cpu().detach().numpy(), (int(outputs_en.cpu().detach().numpy().shape[0]/2), 2))\n",
    "        pred_encode[i, ::] = pred_burst\n",
    "    pred_data = np.reshape(pred_encode, (-1, 200, 2))\n",
    "    real_data = np.reshape(train_dataset, (-1, 200, 2))\n",
    "\n",
    "    pred_data_av = np.average(pred_data, axis = 1)\n",
    "    real_data_av = np.average(real_data, axis = 1)\n",
    "\n",
    "    real_distance = []\n",
    "    pred_distance = []\n",
    "\n",
    "    for d in range(samples):\n",
    "        point_1 = np.random.randint(0, pred_data_av.shape[0])\n",
    "        point_2 = np.random.randint(0, pred_data_av.shape[0])\n",
    "\n",
    "        dist_pred = spatial.distance.euclidean(pred_data_av[point_1], pred_data_av[point_2])\n",
    "        dist_real = spatial.distance.euclidean(real_data_av[point_1], real_data_av[point_2])\n",
    "\n",
    "        real_distance.append(dist_real)\n",
    "        pred_distance.append(dist_pred)\n",
    "\n",
    "    return real_distance, pred_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhxGPPNfM2iu"
   },
   "outputs": [],
   "source": [
    "#Plot the results\n",
    "real_distance, pred_distance = distance_plot(samples = 2000)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel(\"Dist. in X\")\n",
    "ax.set_xlabel(\"Dist. in ρ\")\n",
    "ax.set(xlabel='Dist. in X', ylabel='Dist. in ρ',\n",
    "      title='Distance Conservation')\n",
    "ax.scatter(real_distance, pred_distance, c='g', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaxY3uCwEgca"
   },
   "source": [
    "### Interploation Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAgFj3cIKhD3"
   },
   "outputs": [],
   "source": [
    "def samples_grid(size= 200, samples=2000, sig_sq=0.01, gaussian = False):\n",
    "    #This function creates a grid passing throught covering areas contained in the training set as well as areas not covered.\n",
    "    center = np.empty(shape = (samples, 2))\n",
    "    step_len = 0.8/(samples/6)\n",
    "    for d in range(int(samples/6)):\n",
    "        center[d, 0] = 0.1\n",
    "        center[d, 1] = 0.1+step_len*d\n",
    "\n",
    "        center[d+int(samples/6), 0] = 0.1+step_len*d\n",
    "        center[d+int(samples/6), 1] = 0.9\n",
    "\n",
    "        center[d+2*int(samples/6), 0] = 0.9\n",
    "        center[d+2*int(samples/6), 1] = 0.1+step_len*d\n",
    "\n",
    "        center[d+3*int(samples/6), 0] = 0.1+step_len*d\n",
    "        center[d+3*int(samples/6), 1] = 0.1\n",
    "\n",
    "        center[d+4*int(samples/6), 0] = 0.6\n",
    "        center[d+4*int(samples/6), 1] = 0.1+step_len*d\n",
    "\n",
    "        center[d+5*int(samples/6), 0] = 0.1+step_len*d\n",
    "        center[d+5*int(samples/6), 1] = 0.6\n",
    "        \n",
    "    points = np.empty(shape = (samples, size, 2))\n",
    "    \n",
    "    for i in range(samples):\n",
    "        pts = np.random.uniform([center[i, 0]-sig_sq, center[i, 1]-sig_sq], [center[i, 0]+sig_sq, center[i, 1]+sig_sq], (size, 2))\n",
    "            \n",
    "        points[i, ::, 0] = pts[::, 0] \n",
    "        points[i, ::, 1] = pts[::, 1] \n",
    "       \n",
    "    return points, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots the grid thagt the model has to reconstruct through its encoder\n",
    "points, center = samples_grid(size= 200, samples=2000, sig_sq=0.01, gaussian = False)\n",
    "points_plt = np.reshape(points, (points.shape[0]*points.shape[1], 2))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Interpolation Test Grid')\n",
    "ax.scatter(center[::, 0], center[::, 1], c='g', alpha=1, s = 4)\n",
    "ax.scatter(points_plt[::, 0], points_plt[::, 1], c='b', alpha=0.006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5t6ys28X6HvV"
   },
   "outputs": [],
   "source": [
    "#Transforms the grid by the same transformationas the train set\n",
    "tran_sq = np.empty_like(points)\n",
    "tran_cent = np.empty_like(center)\n",
    "\n",
    "for i in range(points.shape[0]):\n",
    "    tran_cent[i, ::] =  deformation(center[i, ::])\n",
    "    tran_cent[i, 0 ] = tran_cent[i, 0] - 1\n",
    "    for j in range(points.shape[1]):\n",
    "        tran_sq[i, j, ::] = deformation(points[i, j, ::])\n",
    "        tran_sq[i, j, 0 ] = tran_sq[i, j, 0] - 1 \n",
    "\n",
    "tran_sq_plt = np.reshape(tran_sq, (tran_sq.shape[0]*tran_sq.shape[1], 2))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Model Input')\n",
    "\n",
    "ax.scatter(tran_sq_plt[::, 0], tran_sq_plt[::, 1], c='b', alpha=0.05)\n",
    "#ax.scatter(tran_cent[::, 0], tran_cent[::, 1], c='r', alpha=0.2)\n",
    "train_dataset = np.reshape(tran_sq, (tran_sq.shape[0]*tran_sq.shape[1], tran_sq.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_msCojS6X_M"
   },
   "outputs": [],
   "source": [
    "#Feeds the transfomed grid through the encoder\n",
    "pred_encode = np.empty_like(train_dataset)\n",
    "for i in range(pred_encode.shape[0]):\n",
    "    Input_1 = torch.from_numpy(train_dataset[i, ::].flatten()).float()\n",
    "    outputs_en = model_ae.forward_encoder(Input_1.cuda())\n",
    "    pred_burst = np.reshape(outputs_en.cpu().detach().numpy(), (int(outputs_en.cpu().detach().numpy().shape[0]/2), 2))\n",
    "    pred_encode[i, ::] = pred_burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKRcv45m7ECw"
   },
   "outputs": [],
   "source": [
    "#Plots the encoder output\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Encoder Output')\n",
    "\n",
    "ax.scatter(pred_encode[::, 0], pred_encode[::, 1], c='b', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cEhm1Q0k7Rc5"
   },
   "outputs": [],
   "source": [
    "#Feeds the Grid though the encoder and decoder\n",
    "pred = np.empty_like(train_dataset)\n",
    "for i in range(train_dataset.shape[0]):\n",
    "    Input_1 = torch.from_numpy(train_dataset[i, ::].flatten()).float()\n",
    "    outputs_en = model_ae.forward_encoder(Input_1.cuda())\n",
    "    outputs_de = model_ae.forward_decoder(outputs_en.float())\n",
    "    pred_burst = np.reshape(outputs_de.cpu().detach().numpy(), (int(outputs_de.cpu().detach().numpy().shape[0]/2), 2))\n",
    "    pred[i, ::] = pred_burst\n",
    "pred = np.reshape(pred, (tran_sq.shape[0], tran_sq.shape[1], tran_sq.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JugGkSD-jlZ"
   },
   "outputs": [],
   "source": [
    "#Plots the decoder output.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set(xlabel='X', ylabel='Y',\n",
    "      title='Decoder Output')\n",
    "ax.scatter(pred[::, ::, 0], pred[::, ::, 1], c='g', alpha=0.1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LOCA_Plane_6_2.ipynb",
   "provenance": [
    {
     "file_id": "1onRfcfq-YfZj7fcCrltSWqF0UpTzjOkk",
     "timestamp": 1593538548017
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
